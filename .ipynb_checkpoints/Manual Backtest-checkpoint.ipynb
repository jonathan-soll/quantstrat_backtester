{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "import datetime\n",
    "import os, os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import Queue as queue\n",
    "except ImportError:\n",
    "    import queue\n",
    "\n",
    "import time\n",
    "\n",
    "from event import MarketEvent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoricCSVDataHandler(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 events,\n",
    "                 csv_dir,\n",
    "                 symbol_list):\n",
    "        '''\n",
    "        Initializes the DataHandler by getting the location of the csv files (csv_dir) and a list of symbols to track.\n",
    "\n",
    "        It assumes all the files are named 'symbol.csv' where 'symbol' is a string in the symbol_list\n",
    "\n",
    "        Parameters:\n",
    "        events - The Event Queue\n",
    "        csv_dir - Absolute directory path to the csv files\n",
    "        symbol_list - A list of symbol strings\n",
    "        '''\n",
    "\n",
    "        self.events = events\n",
    "        self.csv_dir = csv_dir\n",
    "        self.symbol_list = symbol_list\n",
    "\n",
    "        self.symbol_data = {}\n",
    "        self.latest_symbol_data = {}\n",
    "        self.continue_backtest = True\n",
    "\n",
    "        self._open_convert_csv_files()\n",
    "        \n",
    "    def _open_convert_csv_files(self):\n",
    "            '''\n",
    "            Opens the CSV files from the data directory, converting them into pandas DataFrames within a symbol dictionary\n",
    "            This handler assumes the data was taken from my database using the following query and then copied into a CSV file\n",
    "            with the name <<symbol>>.csv.\n",
    "\n",
    "            SELECT\n",
    "                p.price_date\n",
    "                , p.open_price\n",
    "                , p.high_price\n",
    "                , p.low_price\n",
    "                , p.close_price\n",
    "                , p.adj_close_price\n",
    "                , p.volume\n",
    "            FROM dbo.daily_price p\n",
    "            JOIN dbo.symbol s ON p.symbol_id = s.id\n",
    "            WHERE\n",
    "                ticker = 'ATVI'\n",
    "            order by price_date\n",
    "            '''\n",
    "\n",
    "            comb_index = None\n",
    "            for s in self.symbol_list: # for each and every symbol we care about\n",
    "                # load the csv file with no head information, indexed on the date\n",
    "                self.symbol_data[s] = pd.io.parsers.read_csv(\n",
    "                    os.path.join(self.csv_dir, '%s.csv' % s),\n",
    "                    header = 0, index_col = 0, parse_dates = True,\n",
    "                    names = [\n",
    "                        'price_date',\n",
    "                        'open_price',\n",
    "                        'high_price',\n",
    "                        'low_price',\n",
    "                        'close_price',\n",
    "                        'adj_close_price',\n",
    "                        'volume'\n",
    "                    ]\n",
    "                ).sort_values(by = 'price_date')   # .sort()\n",
    "\n",
    "                # combine the index to pad forward values\n",
    "                if comb_index is None: # if it's the first symbol, set the index to the dates of the first symbol\n",
    "                    comb_index = self.symbol_data[s].index\n",
    "                else: # if it's not the first symbol, combine the dates of all of the symbols\n",
    "                    comb_index.union(self.symbol_data[s].index)\n",
    "\n",
    "                # set the latest symbol data to None\n",
    "                self.latest_symbol_data[s] = []\n",
    "\n",
    "            # Reindex the dataframes and turn them into row generators instead of actual data frames\n",
    "            for s in self.symbol_list:\n",
    "                self.symbol_data[s] = self.symbol_data[s].reindex(index=comb_index, method = 'pad').iterrows()\n",
    "                \n",
    "    def _get_new_bar(self, symbol):\n",
    "        '''\n",
    "        Returns the latest bar from the data feed.\n",
    "        '''\n",
    "        for b in self.symbol_data[symbol]:\n",
    "            yield b # return a new bar but don't store it in memory, (return it and then throw it away)\n",
    "            \n",
    "    def get_latest_bar(self, symbol):\n",
    "        '''\n",
    "        Returns the last bar from the latest_symbol list\n",
    "        '''\n",
    "        try:\n",
    "            bars_list = self.latest_symbol_data[symbol]\n",
    "        except KeyError:\n",
    "            print('That symbol is not in the historical data set.')\n",
    "            raise\n",
    "        else:\n",
    "            return bars_list[-1]\n",
    "        \n",
    "    def update_bars(self):\n",
    "        '''\n",
    "        Pushes the latest bar to the latest_symbol_data structure for all symbols in the symbol list\n",
    "        '''\n",
    "\n",
    "        for s in self.symbol_list:\n",
    "            try:\n",
    "                print('here1')\n",
    "                bar = next(self._get_new_bar(s)) # grab the new bar\n",
    "            except StopIteration:\n",
    "                print('here2')\n",
    "                self.continue_backtest = False # of there is no next bar then the backtest is over\n",
    "            else:\n",
    "                print('here3')\n",
    "                if bar is not None:\n",
    "                    print('here4')\n",
    "                    self.latest_symbol_data[s].append(bar) # tack the next bar onto the latest_symbol_data\n",
    "        self.events.put(MarketEvent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = r'C:\\Users\\jonat\\Documents\\Projects\\Quantstrat\\First_Backtester\\Data\\\\' #r'C:\\Users\\jonat\\Documents\\Projects\\Quantstrat\\\\'\n",
    "symbol_list = ['ATVI']\n",
    "events = queue.Queue()\n",
    "\n",
    "datahandler = HistoricCSVDataHandler(csv_dir=csv_dir, events=events, symbol_list=symbol_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DataFrame.iterrows at 0x0000027715E18678>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datahandler.symbol_data['ATVI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "here1\n",
      "here3\n",
      "here4\n"
     ]
    }
   ],
   "source": [
    "# manually go through backtest\n",
    "\n",
    "if datahandler.continue_backtest == True:\n",
    "    print('hey')\n",
    "    datahandler.update_bars()\n",
    "else:\n",
    "    print('yo')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2000-01-12 00:00:00'), open_price             17.2500\n",
       " high_price             17.2500\n",
       " low_price              16.3700\n",
       " close_price            16.9400\n",
       " adj_close_price         1.2904\n",
       " volume             224017.0000\n",
       " Name: 2000-01-12 00:00:00, dtype: float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datahandler.symbol_data['ATVI'].__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = r'C:\\Users\\jonat\\Documents\\Projects\\Quantstrat\\First_Backtester\\Data\\\\'\n",
    "\n",
    "symbol_data = {}\n",
    "latest_symbol_data = {}\n",
    "\n",
    "comb_index = None\n",
    "s = 'ATVI'\n",
    "\n",
    "symbol_data[s] = pd.io.parsers.read_csv(\n",
    "    os.path.join(csv_dir, '%s.csv' % s),\n",
    "    header = 0, index_col = 0, parse_dates = True,\n",
    "    names = [\n",
    "        'price_date',\n",
    "        'open_price',\n",
    "        'high_price',\n",
    "        'low_price',\n",
    "        'close_price',\n",
    "        'adj_close_price',\n",
    "        'volume'\n",
    "    ]\n",
    ").sort_values(by = 'price_date')   # .sort()\n",
    "\n",
    "# combine the index to pad forward values\n",
    "if comb_index is None: # if it's the first symbol, set the index to the dates of the first symbol\n",
    "    comb_index = symbol_data[s].index\n",
    "else: # if it's not the first symbol, combine the dates of all of the symbols\n",
    "    comb_index.union(symbol_data[s].index)\n",
    "\n",
    "# set the latest symbol data to None\n",
    "latest_symbol_data[s] = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (algotrading2)",
   "language": "python",
   "name": "algotrading2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
